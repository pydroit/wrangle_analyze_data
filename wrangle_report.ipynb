{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center\"> Wrangle Report </h1>\n",
    "\n",
    "## WeRateDogs; Twitter Analysis of Dog Rating\n",
    "\n",
    "**WeRateDogs** is a Twitter account that rates people's dogs with a humorous comment about the dog.\n",
    "\n",
    "This project aimed at generating insights from twitter data about dog ratings.\n",
    "Three wrangling processes are followed in achieving this:\n",
    "\n",
    "1. Gather\n",
    "2. Assess\n",
    "3. Clean\n",
    "\n",
    "## Gather\n",
    "Data was gotten from three sources:\n",
    "\n",
    "_WeRateDogs Twitter Archive Data_: This is manually downloaded and uploaded to Jupyter Notebook. File name is twitter-archive-enhanced.csv.\n",
    "\n",
    "_Tweet Image Prediction_: Though this is a tsv file, it is hosted on Udacity's servers and is to be programmatically downloaded. The Requests library is used to download the file Ã¬mage_predictions.tsv from this URL here.\n",
    "\n",
    "_Additional data from Tweepy library via the Twitter API_: Additional data is queried from the twitter API to add more details and analysis to the report. Retweet Count and Favorite Count by Twitter IDs will be queried.\n",
    "\n",
    "## Assess\n",
    "After the data was gathered from the different sources, this is then visually and programmatically assessed to identify possible **quality** and **tidiness** issues.\n",
    "\n",
    "The issues identifed are:\n",
    "\n",
    "###### Quality issues\n",
    "1. Since only original ratings are needed, the replies and retweets are not necessary for the analysis.\n",
    "\n",
    "\n",
    "2. Tweets that have no image and even retweets/replies are included in the data.\n",
    "\n",
    "\n",
    "3. Since there's no need for retweets and replies, some columns are extraneous in the data.\n",
    "\n",
    "\n",
    "4. The 'timestamp' column has a consistent tailing '+0000' which is unnecessary.\n",
    "\n",
    "\n",
    "5. The 'source' column in the dataset still has unneeded html elements which make the column not easy to read and use.\n",
    "\n",
    "\n",
    "6. The timestamp field has the wrong datatype. This is to be converted to datetime.\n",
    "\n",
    "\n",
    "7. Inconsistent letter case in the 'p1', 'p2' and 'p3' columns as some are lower case while some are sentence case.\n",
    "\n",
    "\n",
    "8. Some columns do not have good descriptive names.\n",
    "\n",
    "\n",
    "###### Tidiness issues\n",
    "1. The analysis will be cleaner and easier if the three datasets (twitter_archive, image_prediction_file, tweet_json_data) were merged into a single DataFrame.\n",
    "\n",
    "2. The doggo, floofer, pupper and puppo columns on the twitter_archive dataset could actually be Melt into a single column and called say, 'dog_type'.\n",
    "\n",
    "## Clean\n",
    "Now we come to the part where we do the cleaning of the aforementioned issues so we can have a clean dataset and consequently a qualit and accurate analysis.\n",
    "\n",
    "1. Since only original ratings are needed, the replies and retweets are not necessary for the analysis.\n",
    "<br>**This was cleaned up by deleting records that are actually replies and retweets**\n",
    "\n",
    "\n",
    "2. Tweets that have no image and even retweets/replies are included in the data.\n",
    "<br>**Since tweets that do not have image are not needed, these were excluded from the data that is to be analysed**\n",
    "\n",
    "\n",
    "3. Since there's no need for retweets and replies, some columns are extraneous in the data.\n",
    "<br>**Columns that exclusively have to do with retweets and replies were removed since they serve no purpose to the data**\n",
    "\n",
    "\n",
    "4. The 'timestamp' column has a consistent trailing '+0000' which is unnecessary.\n",
    "<br>**The unnecessary trailing '+0000' after each value in the timestamp column was removed with regex expression**\n",
    "\n",
    "\n",
    "5. The 'source' column in the dataset still has unneeded html elements which make the column not easy to read and use.\n",
    "<br>**The source of tweet was cleaned-up with the use of regex expression**\n",
    "\n",
    "\n",
    "6. The timestamp field has the wrong datatype. This is to be converted to datetime.\n",
    "<br>**The timestamp column that had an object datatype was converted to a datetime datatype using the pandas' to_datetime**\n",
    "\n",
    "\n",
    "7. Inconsistent letter case in the 'p1', 'p2' and 'p3' columns as some are lower case while some are sentence case.\n",
    "<br>**The 'p1', 'p2' and 'p3' columns were converted to lowercase**\n",
    "\n",
    "\n",
    "8. Some columns do not have good descriptive names.\n",
    "<br>**The necessary columns were renamed appropraitely**\n",
    "\n",
    "\n",
    "9. The analysis will be cleaner and easier if the three datasets (twitter_archive, image_prediction_file, tweet_json_data) were merged into a single DataFrame.\n",
    "<br>**The three datasets were merged together using the merge function in pandas**\n",
    "\n",
    "\n",
    "10. The doggo, floofer, pupper and puppo columns on the twitter_archive dataset could actually be Melt into a single column and called say, 'dog_type'.\n",
    "<br>**These columns were converted into a single column using the melt function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
